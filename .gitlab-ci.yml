# --------------------( LICENSE                            )--------------------
# Copyright 2014-2016 by Alexis Pietak & Cecil Curry.
# See "LICENSE" for further details.
#
# --------------------( SYNOPSIS                           )--------------------
# Project-wide GitLab-CI configuration, integrating the in-house free-as-in-beer
# continuous integration (CI) service exposed by GitLab with this project's
# "py.test"-driven test suite. GitLab-specific terminology used by this service
# includes (from highest- to lowest-level):
#
# * GitLab-CI, GitLab's high-level CI service coordinating project-specific and
#   shared Runners with projects - including project artefacts and metadata.
# * Runner, a low-level virtual machine conforming to the GitLab Runner API and
#   acquiring builds to process through the GitLab-CI coordinator API. There
#   exist two categories of Runners:
#   * Project Runners, hosted either directly by project maintainers on private
#     servers *OR* indirectly by for-profit intermediaries on private servers
#     paid for by the project maintainers. As the nomenclature implies, Project
#     Runners are specific to and hence accessible by only the project to which
#     they are assigned. In either case, "paid" and "private" are the general
#     keywords here. (Inapplicable for our use case.)
#   * Shared Runners. As the nomenclature implies, Shared Runners are accessible
#     to all projects on a GitLab instance. Hence, all projects hosted by the
#     official gitlab.com share access to the same Shared Runners. Shared
#     Runners are hosted either:
#     * If the GitLab instance hosting this project is *NOT* the official
#       gitlab.com, then by the prior mechanisms (e.g., by project maintainers
#       or for-profit intermediaries).
#     * If the GitLab instance hosting this project is the official gitlab.com,
#       then by the for-profit intermediary with whom gitlab.com has partnered:
#       as of this writing, DigitalOcean. In this and only this special
#       edge-case, Shared Runners are free-as-in-beer for both public and
#       private repositories hosted with this instance. An inevitable caveat, of
#       course, is that only Linux-based Shared Runners are available. To quote
#       the official response to a recent issue report requesting both OS X and
#       Windows support:
#       "If you are writing about shared runners on GitLab.com, then they are
#        only Linux based (with docker executor). If you need Windows, Mac or
#        any other OS for the runner, then you need to install it on your own
#        host and register it in your project on GitLab.com."
#
# This gitlab.com-hosted project has been configured to enable Linux-based
# Shared Runners. Exercising tests on either OS X or Windows requires doing so
# on an external third-party free-as-in-beer CI service specific to that
# platform and then integrating such service with GitLab.

#FIXME: Replace use of the default pip cache with "pip-accel", which appears to
#be substantially faster. For now, pip cache is better than no cache.

# ....................{ DOCKER                             }....................
# Colon-delimited name and tag of the first- or third-party Docker image
# registered with the Docker Hub Registery (e.g., "python:3", denoting the
# Docker image named "python" tagged as "3"), provisioning the scientific stack
# to be tested against. A tag is an alphanumeric label unique to an image,
# whose name is itself an alphanumeric label unique to the set of all images
# registered with the Docker Hub Registery. A tag typically specifies the
# version of that image to be used.
#
# For a list of all available Docker images, see the search bar at the top of
# "https://hub.docker.com". To find relevant images, consider (in order):
#
# * Either:
#   * Google "docker python3 matplotlib". Since Matplotlib transitively requires
#     most dependencies required by this project, this query (typically) yields
#     maximally relevant images.
#   * Search the Docker Hub Registry directly by:
#     * Switching the list box from its useless default of "All" to either
#       "Downloads" or "Stars", sorting hits on image usage or upvotes.
#     * Searching for "python". Unfortunately, since the search engine *ONLY*
#       searches image names rather than some combination of names,
#       descriptions, and/or Dockerfiles, the resulting hits tend to be only
#       minimally relevant.
# * For each image of interest, clicking the "Tags" subpage to list:
#   * All available tags for that image.
#   * For each such tag, the compressed filesize of that tagged image.
#
# All else being equal, the smallest image pre-packaging the largest number of
# dependencies required for our scientific stack is the most ideal. Note that
# downloading and installing dependencies via a package manager is significantly
# slower than merely downloading an image pre-packaging those dependencies.
#
# Docker official images are rumoured to be switching from an Ubuntu- to an
# Alpine Linux-based OS. Thanks to an obsessive-compulsive attention to
# minification, Alpine Linux is ideal for Docker-based CI. While Alpine Linux
# comes bundled with a package manager ("apk") providing a variety of scientific
# Python packages (e.g., "py-numpy"), these packages are all specific to the
# Python 2.7 ecosystem as of mid-2016. If and when Alpine Linux provides new
# Python 3.x-compatible scientific Python packages, the current choice of Docker
# image below should be revisited.
#
# For simplicity, we currently fallback to the official Anaconda 3 Docker image
# from Continuum Analytics. If and when Alpine Linux supports Python 3.x,
# consider a (probably painful and hence improbable) switch. See also:
#
# * Docker Hub Registery entry for this image:
#   https://hub.docker.com/r/continuumio/anaconda3
# * Open-source GitHub repository hosting this image's Dockerfile:
#   https://github.com/ContinuumIO/docker-images/tree/master/anaconda3
# * Platform-specific lists of all Anaconda packages installed by default:
#   http://repo.continuum.io/pkgs
# * A promising alternative installing additional optional dependencies over
#   Anaconda 3, including FFMpeg. It's fairly heavyweight (which is bad), but
#   frequently maintained (which is good):
#   https://hub.docker.com/r/kaggle/python
#   https://github.com/Kaggle/docker-python
# * A promising alternative layering Anaconda 3 onto Alpine Linux, thus
#   circumventing several of the aforementioned issues. Unfortunately, this
#   image is infrequently maintained and hence unreliable (which is terribad):
#   https://github.com/vishnu2kmohan/anaconda3-docker
image: continuumio/anaconda3

# ....................{ GLOBALS                            }....................
# Dictionary mapping from the name to value of each environment variable to be
# "globally" exported and hence accessible to *ALL* commands run below.
variables:
  # ...................{ GLOBALS ~ public                   }...................
  # Public environment variables specific to third-party applications.

  # Instruct Matplotlib to cache metadata to the build-relative directory
  # repeated in the "cache:" section below.
  MPLCONFIGDIR: "mpl-cache"

  # Instruct "pip" to cache all downloads to the build-relative directory
  # repeated in the "cache:" section below.
  # PIP_CACHE_DIR: "pip-cache"

  # ...................{ GLOBALS ~ private                  }...................
  # Private environment variables specific to this configuration. To avoid
  # conflict with third-party applications, the name of each such variable is
  # intentionally prefixed by "_".

  # Relative path of the top-level directory containing this configuration's
  # Ananconda environment repeated in the "cache:" section below. To
  # differentiate this environment from an environment of the same name in the
  # default system-wide directory for Anaconda environments (e.g.,
  # "/opt/conda/envs"), this path is intentionally prefixed by "./".
  _CONDA_ENV_DIRNAME: "./conda-env"


cache:
  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  # WARNING: Due to an outstanding issue, GitLab-CI currently ignores *ALL*
  # cache paths outside the build directory. See also:
  #     https://gitlab.com/gitlab-org/gitlab-ce/issues/4431
  # Sadly, this implies that cache paths listed below *MUST* be both relative to
  # and contained in the build directory. Ensure that each such path is prefixed
  # by neither "/", "./", or "../" *OR* by any variable expanding to such a path
  # (e.g., "$HOME").
  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  #
  # List of the relative or absolute paths of all directories to be preserved
  # between CI pipelines. (Note that relative paths are relative to the current
  # build directory.)
  paths:
    # The directory to which "conda" persists Anaconda environments.
    - conda-envs

    # The directory to which Matplotlib caches metadata (e.g., on fonts).
    - mpl-cache

    # The directory to which pip caches artifacts pertaining to previously
    # installed and possibly compiled dependencies.
    # - pip-cache
    # - $HOME/.cache/pip

# ....................{ DEPENDENCIES                       }....................
# List of all external commands to be run *FIRST* for this CI pipeline.
before_script:
  # Update all system packages installed by default with this image for the
  # duration of this CI pipeline.
  #
  # Since this image is frequently updated, this is ignored.
  #- apt-get update -qy

  # Install all dependencies available via the system-wide package manager,
  # which is typically both faster and stabler than doing so via pip3.
  #
  # Since this image provides all such dependencies by default, this is ignored.
  # - apt-get install -y

  #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
  # WARNING: Since this pipeline currently leverages the Anaconda-based "conda"
  # manager rather than the pure-Python "pip" manager to install dependencies,
  # the following command is vestigial and is preserved only for posterity.
  #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

  # Install all Python-specific dependencies via "pip". Dismantled, this is:
  #
  # * "--quiet", reducing output verbosity.
  # * "--disable-pip-version-check", improving both space and time complexity by
  #   preventing "pip" from unnecessarily upgrading itself.
  # * "--cache-dir", redefining the same directory exported as an environment
  #   variable above. While redundant, doing so increases the likelihood that
  #   "pip" will actually respect this cache request.
  # * "--upgrade-strategy", improving both space and time complexity by
  #   preventing "pip" from unnecessarily upgrading dependencies already
  #   satisfying application requirements.
  # * "--requirement", the relative path of the file listing all dependencies to
  #   be installed.
  # - pip3 --quiet --disable-pip-version-check --cache-dir "${PIP_CACHE_DIR}" install --upgrade-strategy only-if-needed --requirement requirements.txt

  # Configure "conda" to run in headless mode. Dismantled, this is:
  #
  # * "always_yes true", automatically pass the "--yes" option to *ALL*
  #   "conda" commands run below. This is a superficial convenience reducing the
  #   likelihood of developer oversight and hence saving essential sanity.
  # * "auto_update_conda false", improving both space and time complexity by
  #   preventing "conda" from unnecessarily upgrading itself.
  - conda config --set always_yes true --set auto_update_conda false

  # For debuggability, print metadata identifying this Anaconda release.
  - conda info --all

  # Create an empty Anaconda environment if not already created by a prior job
  # *OR* fail with an ignorable error otherwise. To ensure this environment is
  # created in a cachable build-local directory rather than the uncachable
  # default directory for Anaconda environments, the "--prefix" rather than
  # "--name" option is passed. Since these two options are mutually exclusive,
  # only the former is passed.
  - conda create --quiet --prefix "${_CONDA_ENV_DIRNAME}"

  # Activate the previously defined environment, prepending the current ${PATH}
  # by this environment's top-level directory.
  - source activate "${_CONDA_ENV_DIRNAME}"

  # Install all mandatory and optional dependencies of this application into
  # this environment.
  #
  # Note that passing the "--file requirements-conda.txt" option to the above
  # "conda create" command would suffice to do so for the initial creation of
  # this environment but fail to account for subsequent changes to these
  # dependencies; hence, environment creation and dependency installation *MUST*
  # be separated. The efficiency hit is minimal if any.
  #
  # Note that isolating the installation of these dependencies into an
  # environment is essential. Although this installation is already confined to
  # a temporary Docker image and hence requires no additional isolation.
  # Anaconda *ONLY* supports configurable caching via the "${CONDA_PREFIX}"
  # environment variable specific to Anaconda environments. To persist this
  # installation across jobs, there exists no sane alternative.
  - conda install --quiet --file requirements-conda.txt

# ....................{ COMMANDS                           }....................
test:
  # List of all external commands to be run for each CI pipeline *AFTER* those
  # listed within "before_script" above.
  script:
    # Run the entire "py.test"-based test suite under the following options:
    #
    # * "--maxfail=3", halting testing on the third failure. For discussion, see
    #   the "betse_setup.test" submodule.
    - py.test --maxfail=3
    # - py.test --maxfail=3 -s
